{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries required\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PREPARING THE DATA FOR THE MODEL</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_ID</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>89.633172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>123.979728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>21.949434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>138.377424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>113.772651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender_ID  Degree  Age      Salary\n",
       "0         -1       2   36   89.633172\n",
       "1         -1       3   47  123.979728\n",
       "2          1       1   26   21.949434\n",
       "3         -1       1   68  138.377424\n",
       "4          1       2   33  113.772651"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Created a dataframe using the data provided in the table. Added noise to the Salary column, with the noise being Normal distribution\n",
    "header=[\"Gender_ID\",\"Degree\",\"Age\",\"Salary\"]\n",
    "#The noise array with five elements, to be added to the salary column.\n",
    "noise=np.random.normal(0,1,5) \n",
    "\n",
    "training_data=[\n",
    "    [-1,-1,+1,-1,+1],\n",
    "    [2,3,1,1,2],\n",
    "    [36,47,26,68,33],\n",
    "    [89.563,123.543,23.989,138.769,113.888]\n",
    "]\n",
    "\n",
    "\n",
    "df=pd.DataFrame(training_data).transpose()\n",
    "df.columns=header\n",
    "\n",
    "\n",
    "#Adding noise to the data.\n",
    "df[\"Salary\"]=[df[\"Salary\"][i]+noise[i] for i in range(len(df))]\n",
    "df.head()\n",
    "#Converting the data types of each column to integer, except the salary colum\n",
    "data_types={\"Gender_ID\":int,\"Degree\":int,\"Age\":int}\n",
    "df.astype(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Made three different attribute datasets: One with only the Age column, one with the Age and Degree column, one with the age,degree and the Gender ID column. \n",
    "X1=np.array(df[[\"Age\"]]).reshape(-1,1)\n",
    "X1=X1.astype(\"int\")\n",
    "X2=np.array(df[[\"Age\",\"Degree\"]]).reshape(-1,2)\n",
    "X2=X2.astype(\"int\")\n",
    "X3=np.array(df[[\"Age\",\"Degree\",\"Gender_ID\"]]).reshape(-1,3)\n",
    "X3=X3.astype(\"int\")\n",
    "#the column with the Salary values.\n",
    "Y=np.array(df[\"Salary\"]).reshape(-1,1)\n",
    "#print(X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>STRAIGHT CURVE FITTING REGRESSION</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the SCF model on data X1:\n",
      "[84.66668391655118, 108.2723134326932, 63.20702072005845, 153.33760614532792, 78.22878495760337]\n",
      "\n",
      "\n",
      "The salary predicted by the straight curve when the age is 60 is: 136.16987558813372\n"
     ]
    }
   ],
   "source": [
    "#For stratight curve fitting regression, I used the existing LinearRegression library in python. The regression model in this cell is for data with only Age column.\n",
    "regr=LinearRegression()\n",
    "regr.fit(X1,Y)\n",
    "#The score evaluating the linear fit for X1 data.\n",
    "score_SCF_X1=regr.score(X1,Y)\n",
    "#prediction_SCF_Xi is the prediction by the linear model for X1 using the Straight curve fitting method. It has the five predictions it made for the five rows of data set in the training set./\n",
    "prediction_SCF_X1=regr.predict(np.array(X1))\n",
    "prediction_SCF_X1=[prediction_SCF_X1[i][0] for i in range(len(X1))]\n",
    "print(\"The prediction by the SCF model on data X1:\")\n",
    "print(prediction_SCF_X1)\n",
    "print(\"\\n\")\n",
    "\n",
    "#This gives the prediction of salary for age 60, as asked in the question\n",
    "y_test=regr.predict(np.array([[60]]))\n",
    "print(\"The salary predicted by the straight curve when the age is 60 is:\",y_test[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the SCF model on data X2:\n",
      "[89.12372023206069, 139.95875451124527, 40.555243081927685, 135.7506425020944, 82.32404884490593]\n"
     ]
    }
   ],
   "source": [
    "#The following two cells are the regression fits for the data X2,X3. They also have a prediction list for them, stored as prediction_<Model_used>_<dataset>\n",
    "regr=LinearRegression()\n",
    "regr.fit(X2,Y)\n",
    "score_SCF_X2=regr.score(X2,Y)\n",
    "prediction_SCF_X2=regr.predict(np.array(X2))\n",
    "prediction_SCF_X2=[prediction_SCF_X2[i][0] for i in range(len(X2))]\n",
    "print(\"The prediction by the SCF model on data X2:\")\n",
    "print(prediction_SCF_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the SCF model on data X3:\n",
      "[74.44198221172991, 140.9070536359166, 40.612896487830184, 136.6412882208632, 95.10918861589408]\n"
     ]
    }
   ],
   "source": [
    "regr=LinearRegression()\n",
    "regr.fit(X3,Y)\n",
    "score_SCF_X3=regr.score(X3,Y)\n",
    "prediction_SCF_X3=regr.predict(np.array(X3))\n",
    "prediction_SCF_X3=[prediction_SCF_X3[i][0] for i in range(len(X3))]\n",
    "print(\"The prediction by the SCF model on data X3:\")\n",
    "print(prediction_SCF_X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MLE REGRESSION MODEL</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function to calculate the likelihood function, given the predicted outcomes, the actual values and the number of samples. It returns the log of the probability.\n",
    "def calcLogLikelihood(guess,true,n):\n",
    "    #error column is how much do the predicted values differ from the true values\n",
    "    error=true-guess \n",
    "    sigma=np.std(error)\n",
    "    #the formula for the likelihood\n",
    "    f=((1.0/(2.0*math.pi*(sigma**2)))**(n/2))* \\\n",
    "        np.exp(-1*((np.dot(error.T,error))/(2*sigma*sigma)))\n",
    "    return np.log(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell has three different models, for the respective datasets. They take in the variable array and return the negative loglikelihood value for that set of variables.\n",
    "def MLE_model1(var):\n",
    "    x,y=np.array(df[\"Age\"]),np.array(df[\"Salary\"])\n",
    "    #predicts the value of y on the basis of the X column.\n",
    "    yguess=np.array([(var[1]*(x[i])+var[0]) for i in range(len(x))])\n",
    "    f=calcLogLikelihood(yguess,y,float(len(yguess)))\n",
    "    return (-1*f)\n",
    "\n",
    "def MLE_model2(var):\n",
    "    x1,x2,y=df[\"Age\"],df[\"Degree\"],df[\"Salary\"]\n",
    "    yguess=[0 for i in range(len(x1))]\n",
    "    yguess=[(var[2]*x2[i]+var[1]*x1[i]+var[0]) for i in range(len(x1))]\n",
    "    f=calcLogLikelihood(yguess,y,float(len(yguess)))\n",
    "    return (-1*f)\n",
    "\n",
    "def MLE_model3(var):\n",
    "    x1,x2,x3,y=df[\"Age\"],df[\"Degree\"],df[\"Gender_ID\"],df[\"Salary\"]\n",
    "    yguess=[0 for i in range(len(x1))]\n",
    "    yguess=[(var[3]*x3[i]+var[2]*x2[i]+var[1]*x1[i]+var[0]) for i in range(len(x1))]\n",
    "    f=calcLogLikelihood(yguess,y,float(len(yguess)))\n",
    "    return (-1*f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the MLE model on data X1:\n",
      "[84.66669632483799, 108.27231462204306, 63.20704332737882, 153.3375859167073, 78.22880042560023]\n"
     ]
    }
   ],
   "source": [
    "#The next three cells are for the estimation of the parameters using the lIkelihood function.  \n",
    "# We minimize the -log  likelihood function instead of maximizing the loglikelihood function.\n",
    "from scipy.optimize import minimize\n",
    "nvar=2\n",
    "var=np.zeros(nvar)\n",
    "#Randomly picked two variable inputs.\n",
    "var[0]=15\n",
    "var[1]=2\n",
    "\n",
    "#This is the minimizing function\n",
    "res1=minimize(MLE_model1,var,method=\"BFGS\",options={\"disp\":False})\n",
    "#print(res1)\n",
    "#res.x1 gives the parameters in an array\n",
    "theta_MLE_1=res1.x\n",
    "prediction_MLE_X1=[theta_MLE_1[0]+theta_MLE_1[1]*X1[i][0] for i in range(len(X1))]\n",
    "print(\"The prediction by the MLE model on data X1:\")\n",
    "print(prediction_MLE_X1)\n",
    "#print(prediction_SCF_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the MLE model on data X2:\n",
      "[89.12369757540722, 139.95881887154366, 40.55513605714182, 135.75064672772592, 82.32401824179405]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "nvar=3\n",
    "var=np.zeros(nvar)\n",
    "var[0]=15\n",
    "var[1]=2\n",
    "var[2]=7\n",
    "\n",
    "res2=minimize(MLE_model2,var,method=\"BFGS\",options={\"disp\":False})\n",
    "#print(res2)\n",
    "theta_MLE_2=res2.x\n",
    "prediction_MLE_X2=[theta_MLE_2[0]+theta_MLE_2[1]*X2[i][0] + theta_MLE_2[2]*X2[i][1] for i in range(len(X2))]\n",
    "print(\"The prediction by the MLE model on data X2:\")\n",
    "print(prediction_MLE_X2)\n",
    "#print(prediction_SCF_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the MLE model on data X3:\n",
      "[74.44196909096411, 140.90710258407978, 40.612854903760805, 136.64124773400155, 95.10920587258315]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "nvar=4\n",
    "var=np.zeros(nvar)\n",
    "var[0]=15\n",
    "var[1]=2\n",
    "var[2]=7\n",
    "var[3]=15\n",
    "\n",
    "res3=minimize(MLE_model3,var,method=\"BFGS\",options={\"disp\":False})\n",
    "#print(res3.x)\n",
    "theta_MLE_3=res3.x\n",
    "prediction_MLE_X3=[theta_MLE_3[0]+theta_MLE_3[1]*X3[i][0] + theta_MLE_3[2]*X3[i][1] + theta_MLE_3[3]*X3[i][2] for i in range(len(X3))]\n",
    "print(\"The prediction by the MLE model on data X3:\")\n",
    "print(prediction_MLE_X3)\n",
    "#print(prediction_SCF_X3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAP REGRESSION MODEL</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell has the MAP models with the probability distribution due to the parameters added to the log likelihood calculated in the previos question.\n",
    "#the distribution has mean zero and variance: Covariance matrix (Identity matrix multiplied by a constant)\n",
    "def MAP_model1(var):\n",
    "    n=len(var)\n",
    "    x,y=np.array(df[\"Age\"]),np.array(df[\"Salary\"])\n",
    "    yguess=np.array([(var[1]*(x[i])+var[0]) for i in range(len(x))])\n",
    "    #The covariance matrix\n",
    "    cov_mat=np.identity(n,dtype=int)*2\n",
    "    var_dist=multivariate_normal.pdf(var,[0]*n,cov_mat)\n",
    "    #Adding the log of the probability for that set of parameters\n",
    "    f=calcLogLikelihood(yguess,y,float(len(yguess)))+np.log(var_dist)\n",
    "    return (-1*f)\n",
    "\n",
    "def MAP_model2(var):\n",
    "    n=len(var)\n",
    "    x1,x2,y=df[\"Age\"],df[\"Degree\"],df[\"Salary\"]\n",
    "    yguess=[0 for i in range(len(x1))]\n",
    "    yguess=[(var[2]*x2[i]+var[1]*x1[i]+var[0]) for i in range(len(x1))]\n",
    "    #The covariance matrix\n",
    "    cov_mat=np.identity(n,dtype=int)*2\n",
    "    var_dist=multivariate_normal.pdf(var,[0]*n,cov_mat)\n",
    "    #Adding the log of the probability for that set of parameters\n",
    "    f=calcLogLikelihood(yguess,y,float(len(yguess)))+np.log(var_dist)\n",
    "    return (-1*f)\n",
    "\n",
    "def MAP_model3(var):\n",
    "    n=len(var)\n",
    "    x1,x2,x3,y=df[\"Age\"],df[\"Degree\"],df[\"Gender_ID\"],df[\"Salary\"]\n",
    "    yguess=[0 for i in range(len(x1))]\n",
    "    yguess=[(var[3]*x3[i]+var[2]*x2[i]+var[1]*x1[i]+var[0]) for i in range(len(x1))]\n",
    "    #The covariance matrix\n",
    "    cov_mat=np.identity(n,dtype=int)*2\n",
    "    var_dist=multivariate_normal.pdf(var,[0]*n,cov_mat)\n",
    "    #Adding the log of the probability for that set of parameters\n",
    "    f=calcLogLikelihood(yguess,y,float(len(yguess)))+np.log(var_dist)\n",
    "    return (-1*f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the MAP model on data X1:\n",
      "[80.13312234650918, 104.60033806061931, 57.89019897004543, 151.31047715119317, 73.46024533357006]\n"
     ]
    }
   ],
   "source": [
    "#The following three cells are the models for minimizing the loss and predicting the results.\n",
    "from scipy.optimize import minimize\n",
    "nvar=2\n",
    "var=np.zeros(nvar)\n",
    "var[0]=15\n",
    "var[1]=2\n",
    "\n",
    "res1=minimize(MAP_model1,var,method=\"BFGS\",options={\"disp\":False})\n",
    "#print(res1.x)\n",
    "theta_MAP_1=res1.x\n",
    "prediction_MAP_X1=[theta_MAP_1[0]+theta_MAP_1[1]*X1[i][0] for i in range(len(X1))]\n",
    "print(\"The prediction by the MAP model on data X1:\")\n",
    "print(prediction_MAP_X1)\n",
    "#print(prediction_SCF_X1)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the MAP model on data X2:\n",
      "[80.37904688323187, 105.0413413002471, 57.930814788700545, 150.92143233302474, 73.73685991578014]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "nvar=3\n",
    "var=np.zeros(nvar)\n",
    "var[0]=15\n",
    "var[1]=2\n",
    "var[2]=7\n",
    "\n",
    "res2=minimize(MAP_model2,var,method=\"BFGS\",options={\"disp\":False})\n",
    "#print(res2)\n",
    "theta_MAP_2=res2.x\n",
    "#print(res2.x)\n",
    "prediction_MAP_X2=[theta_MAP_2[0]+theta_MAP_2[1]*X2[i][0] + theta_MAP_2[2]*X2[i][1] for i in range(len(X2))]\n",
    "print(\"The prediction by the MAP model on data X2:\")\n",
    "print(prediction_MAP_X2)\n",
    "#print(prediction_SCF_X2)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by the MAP model on data X3:\n",
      "[80.40197240906491, 105.06118740061162, 57.89056513544832, 150.9351937137546, 73.69466977385676]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "nvar=4\n",
    "var=np.zeros(nvar)\n",
    "var[0]=15\n",
    "var[1]=2\n",
    "var[2]=7\n",
    "var[3]=15\n",
    "\n",
    "res3=minimize(MAP_model3,var,method=\"BFGS\",options={\"disp\":False})\n",
    "#print(res3.x)\n",
    "theta_MAP_3=res3.x\n",
    "prediction_MAP_X3=[theta_MAP_3[0]+theta_MAP_3[1]*X3[i][0] + theta_MAP_3[2]*X3[i][1] + theta_MAP_3[3]*X3[i][2] for i in range(len(X3))]\n",
    "print(\"The prediction by the MAP model on data X3:\")\n",
    "print(prediction_MAP_X3)\n",
    "#print(prediction_SCF_X3)\n",
    "#print(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> THE SUMMARY </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct values of y, as given in the data are: [89.63317232669303, 123.9797275078149, 21.94943434658975, 138.37742423400192, 113.7726507571345]\n"
     ]
    }
   ],
   "source": [
    "y=[Y[i][0] for i in range(len(Y))]\n",
    "print(\"The correct values of y, as given in the data are:\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When age is the only parameter:\n",
      "\t Predictions by the Straight curve fit model are: [84.66668391655118, 108.2723134326932, 63.20702072005845, 153.33760614532792, 78.22878495760337]\n",
      "\t Predictions by the MLE model are: [84.66669632483799, 108.27231462204306, 63.20704332737882, 153.3375859167073, 78.22880042560023]\n",
      "\t Predictions by the MAP model are: [80.13312234650918, 104.60033806061931, 57.89019897004543, 151.31047715119317, 73.46024533357006]\n"
     ]
    }
   ],
   "source": [
    "print(\"When age is the only parameter:\")\n",
    "print(\"\\t Predictions by the Straight curve fit model are:\", prediction_SCF_X1)\n",
    "print(\"\\t Predictions by the MLE model are:\", prediction_MLE_X1)\n",
    "print(\"\\t Predictions by the MAP model are:\", prediction_MAP_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When age, Degree are the parameters:\n",
      "\t Predictions by the Straight curve fit model are: [89.12372023206069, 139.95875451124527, 40.555243081927685, 135.7506425020944, 82.32404884490593]\n",
      "\t Predictions by the MLE model are: [89.12369757540722, 139.95881887154366, 40.55513605714182, 135.75064672772592, 82.32401824179405]\n",
      "\t Predictions by the MAP model are: [80.37904688323187, 105.0413413002471, 57.930814788700545, 150.92143233302474, 73.73685991578014]\n"
     ]
    }
   ],
   "source": [
    "print(\"When age, degree are the parameters:\")\n",
    "print(\"\\t Predictions by the Straight curve fit model are:\", prediction_SCF_X2)\n",
    "print(\"\\t Predictions by the MLE model are:\", prediction_MLE_X2)\n",
    "print(\"\\t Predictions by the MAP model are:\", prediction_MAP_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When age, degree and gender are the parameters:\n",
      "\t Predictions by the Straight curve fit model are: [74.44198221172991, 140.9070536359166, 40.612896487830184, 136.6412882208632, 95.10918861589408]\n",
      "\t Predictions by the MLE model are: [74.44196909096411, 140.90710258407978, 40.612854903760805, 136.64124773400155, 95.10920587258315]\n",
      "\t Predictions by the MAP model are: [80.40197240906491, 105.06118740061162, 57.89056513544832, 150.9351937137546, 73.69466977385676]\n"
     ]
    }
   ],
   "source": [
    "print(\"When age, degree and gender are the parameters:\")\n",
    "print(\"\\t Predictions by the Straight curve fit model are:\", prediction_SCF_X3)\n",
    "print(\"\\t Predictions by the MLE model are:\", prediction_MLE_X3)\n",
    "print(\"\\t Predictions by the MAP model are:\", prediction_MAP_X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions for the MLE and the straight curve fitting model are the same. MAP models give slightly different answers. The predictions for the MAP models also depend on the value of the lambda for the covariance matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean squared error for MAP Model using data X1 is:  709.9808270966814\n",
      "The Mean squared error for MLE Model using data X1 is:  692.1501472431992\n"
     ]
    }
   ],
   "source": [
    "sq_error_MAP_X1=[(prediction_MAP_X1[i]-y[i])**2 for i in range(len(y))]\n",
    "mean_sq_error_MAP_X1=(sum(sq_error_MAP_X1)/len(y))\n",
    "print(\"The Mean squared error for MAP Model using data X1 is: \", mean_sq_error_MAP_X1)\n",
    "sq_error_MLE_X1=[(prediction_MLE_X1[i]-y[i])**2 for i in range(len(y))]\n",
    "mean_sq_error_MLE_X1=(sum(sq_error_MLE_X1)/len(y))\n",
    "print(\"The Mean squared error for MLE Model using data X1 is: \", mean_sq_error_MLE_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean squared error for MAP Model using data X2 is:  699.8355471742492\n",
      "The Mean squared error for MLE Model using data X2 is:  319.53590172540703\n"
     ]
    }
   ],
   "source": [
    "sq_error_MAP_X2=[(prediction_MAP_X2[i]-y[i])**2 for i in range(len(y))]\n",
    "mean_sq_error_MAP_X2=(sum(sq_error_MAP_X2)/len(y))\n",
    "print(\"The Mean squared error for MAP Model using data X2 is: \", mean_sq_error_MAP_X2)\n",
    "sq_error_MLE_X2=[(prediction_MLE_X2[i]-y[i])**2 for i in range(len(y))]\n",
    "mean_sq_error_MLE_X2=(sum(sq_error_MLE_X2)/len(y))\n",
    "print(\"The Mean squared error for MLE Model using data X2 is: \", mean_sq_error_MLE_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean squared error for MAP Model using data X3 is:  699.7666456182988\n",
      "The Mean squared error for MLE Model using data X3 is:  243.3940866826898\n"
     ]
    }
   ],
   "source": [
    "sq_error_MAP_X3=[(prediction_MAP_X3[i]-y[i])**2 for i in range(len(y))]\n",
    "mean_sq_error_MAP_X3=(sum(sq_error_MAP_X3)/len(y))\n",
    "print(\"The Mean squared error for MAP Model using data X3 is: \", mean_sq_error_MAP_X3)\n",
    "sq_error_MLE_X3=[(prediction_MLE_X3[i]-y[i])**2 for i in range(len(y))]\n",
    "mean_sq_error_MLE_X3=(sum(sq_error_MLE_X3)/len(y))\n",
    "print(\"The Mean squared error for MLE Model using data X3 is: \", mean_sq_error_MLE_X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> CONCLUSION </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLE and Straight Curve fitting models give almost the same result. \n",
    "The MAP model, on the other hand, gives a different prediction. \n",
    "The results from the MAP model also depend on the value of lambda in the covariance matrix. \n",
    "While the MAP model is expected to perform better, in this case, the MLE gives a lower loss and therefore a better result. \n",
    "This could be due to the fact that the function does not have a zero-one loss on the function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9e4803da988dc070712e37fe1ba1df1cb4573f2fe7d9fe88b0c597a7c79a9a8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
